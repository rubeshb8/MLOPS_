{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31f4cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (1.62.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-genai) (4.12.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai) (2.48.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-genai) (2.12.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-genai) (9.1.4)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-genai) (4.15.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-genai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-genai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: cryptography>=38.0.3 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (46.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.6.3)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (0.6.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\runain\\onedrive - ifs\\documents\\mlops_\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install google-genai --trusted-host pypi.org --trusted-host files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d048bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: python-dotenv\n",
      "Version: 1.2.1\n",
      "Summary: Read key-value pairs from a .env file and set them as environment variables\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Saurabh Kumar <me+github@saurabh-kumar.com>\n",
      "License: \n",
      "Location: c:\\Users\\runain\\OneDrive - IFS\\Documents\\MLOPS_\\.venv\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8349718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi RBN, that's fantastic that you're diving into MLOps! It's a critical and rapidly growing field.\n",
      "\n",
      "Let's break down MLOps in an easy-to-understand way.\n",
      "\n",
      "---\n",
      "\n",
      "## What is MLOps?\n",
      "\n",
      "At its core, **MLOps (Machine Learning Operations)** is a set of practices, principles, and tools that aim to **streamline the entire lifecycle of Machine Learning models**, from experimentation and development to deployment, monitoring, and maintenance in production.\n",
      "\n",
      "Think of it as the intersection of:\n",
      "1.  **Machine Learning:** The data science, model building, and algorithms.\n",
      "2.  **DevOps:** The software engineering practices for continuous integration, delivery, and deployment.\n",
      "3.  **Data Engineering:** The processes for data collection, transformation, and management.\n",
      "\n",
      "The main goal of MLOps is to **bridge the gap between ML research/experimentation and putting robust, reliable, and scalable ML models into real-world use.**\n",
      "\n",
      "---\n",
      "\n",
      "## Why is MLOps Necessary? (The Problem It Solves)\n",
      "\n",
      "Without MLOps, deploying and managing ML models can be chaotic and ineffective because:\n",
      "\n",
      "1.  **ML models are not static software:** Unlike traditional software that, once deployed, often runs stably for long periods, ML models degrade over time (due to data drift, concept drift). They need continuous monitoring and retraining.\n",
      "2.  **Complexity:** ML systems involve more than just code. They include data pipelines, feature engineering, model training, model serving, and infrastructure.\n",
      "3.  **Reproducibility:** It's hard to track which model version was trained with which data and hyper-parameters, making it difficult to reproduce results or debug issues.\n",
      "4.  **Collaboration:** Data scientists, ML engineers, and operations teams need to work together seamlessly.\n",
      "5.  **Scalability:** Models need to handle varying loads and scale efficiently.\n",
      "6.  **Governance & Compliance:** Ensuring models are fair, transparent, and meet regulatory requirements.\n",
      "\n",
      "---\n",
      "\n",
      "## Key Pillars and Stages of MLOps\n",
      "\n",
      "MLOps covers the entire ML lifecycle, focusing on automation, reproducibility, and continuous improvement at each stage:\n",
      "\n",
      "### 1. Data Management & Preparation\n",
      "\n",
      "*   **Data Ingestion & Validation:** Gathering data from various sources and ensuring its quality, consistency, and completeness.\n",
      "*   **Feature Engineering:** Creating relevant features from raw data.\n",
      "*   **Data Versioning:** Tracking changes to datasets, ensuring that models can be retrained on specific versions of data.\n",
      "*   **Feature Store:** A centralized repository for sharing and managing curated features across different models and teams, ensuring consistency between training and inference.\n",
      "\n",
      "### 2. Experimentation & Model Development\n",
      "\n",
      "*   **Model Training & Evaluation:** Iterating on different algorithms, architectures, and hyperparameters.\n",
      "*   **Experiment Tracking:** Logging all relevant information (code, data versions, hyperparameters, metrics, artifacts) for each experiment, making it reproducible and auditable.\n",
      "*   **Code Versioning:** Using Git or similar tools to track changes to the model code and training scripts.\n",
      "\n",
      "### 3. Model Versioning & Registry\n",
      "\n",
      "*   **Model Registry:** A centralized repository to store, version, and manage trained models. It tracks metadata like metrics, associated code, and dataset used.\n",
      "*   **Model Lifecycle Management:** Moving models through stages like Staging, Production, Archived.\n",
      "\n",
      "### 4. CI/CD for ML (Continuous Integration/Continuous Delivery)\n",
      "\n",
      "This is where the \"Ops\" really comes in, adapted for ML:\n",
      "\n",
      "*   **Continuous Integration (CI):**\n",
      "    *   Automated testing of code changes.\n",
      "    *   Automated data validation (checking for schema changes, missing values).\n",
      "    *   Automated model validation (checking if a newly trained model meets minimum performance thresholds before deployment).\n",
      "    *   Building deployment artifacts (e.g., Docker images for model serving).\n",
      "*   **Continuous Delivery/Deployment (CD):**\n",
      "    *   Automated deployment of trained models to various environments (staging, production).\n",
      "    *   Strategies like A/B testing, Canary deployments, or Blue/Green deployments for safe rollouts.\n",
      "\n",
      "### 5. Model Serving & Deployment\n",
      "\n",
      "*   **Real-time Inference:** Deploying models as API endpoints (e.g., REST APIs) for synchronous predictions.\n",
      "*   **Batch Inference:** Processing large datasets asynchronously to generate predictions.\n",
      "*   **Scalability:** Ensuring the model serving infrastructure can handle varying request loads.\n",
      "*   **Latency:** Optimizing for fast response times.\n",
      "\n",
      "### 6. Monitoring & Alerting\n",
      "\n",
      "This is crucial for the long-term health of ML models:\n",
      "\n",
      "*   **Operational Monitoring:** Tracking infrastructure health (CPU, memory, network), latency, error rates of the model serving API.\n",
      "*   **Model Performance Monitoring:** Continuously evaluating the model's accuracy, precision, recall, F1-score, etc., on live data.\n",
      "*   **Data Drift Detection:** Identifying changes in the input data distribution that might degrade model performance.\n",
      "*   **Concept Drift Detection:** Identifying changes in the relationship between input features and the target variable.\n",
      "*   **Bias & Fairness Monitoring:** Ensuring the model continues to make fair predictions across different demographic groups.\n",
      "*   **Alerting:** Setting up notifications when thresholds are breached (e.g., accuracy drops below a certain level, data drift detected).\n",
      "\n",
      "### 7. Governance & Reproducibility\n",
      "\n",
      "*   **Audit Trails:** Documenting who did what, when, and why.\n",
      "*   **Lineage Tracking:** Tracing back every prediction to the specific model, data, and code version used.\n",
      "*   **Explainability (XAI):** Understanding why a model made a particular prediction, especially important in regulated industries.\n",
      "\n",
      "---\n",
      "\n",
      "## Benefits of Implementing MLOps\n",
      "\n",
      "*   **Faster Model Deployment:** Reduce the time from model development to production.\n",
      "*   **Increased Reliability:** Ensure models perform consistently and predictably in production.\n",
      "*   **Better Model Performance:** Continuous monitoring and automated retraining lead to improved model quality over time.\n",
      "*   **Improved Collaboration:** Enables seamless teamwork between data scientists, ML engineers, and operations.\n",
      "*   **Reproducibility & Auditability:** Easily reproduce past results and understand model behavior.\n",
      "*   **Scalability & Cost Efficiency:** Efficiently manage resources and scale ML workloads.\n",
      "*   **Reduced Risk:** Minimize the chances of model failures, performance degradation, or compliance issues.\n",
      "\n",
      "---\n",
      "\n",
      "## Getting Started with MLOps\n",
      "\n",
      "Since you're practicing, here's some practical advice:\n",
      "\n",
      "1.  **Start with the basics:** Understand core DevOps concepts first (CI/CD, containerization like Docker, orchestration like Kubernetes).\n",
      "2.  **Pick a tool/platform:** Many cloud providers offer integrated MLOps platforms (AWS Sagemaker, GCP Vertex AI, Azure ML). Open-source tools like MLflow, Kubeflow, DVC, Airflow are also popular.\n",
      "3.  **Hands-on project:** Take a simple ML project you've done (e.g., predicting house prices, classifying images) and try to apply MLOps principles to it.\n",
      "    *   Version your code with Git.\n",
      "    *   Track your experiments with MLflow.\n",
      "    *   Containerize your model for serving with Docker.\n",
      "    *   Simulate monitoring by generating some \"production\" data and checking performance.\n",
      "4.  **Focus on one problem at a time:** Don't try to implement everything at once. Maybe start with experiment tracking, then move to model deployment, then monitoring.\n",
      "\n",
      "MLOps is a journey, not a destination. It's about building a robust, automated, and collaborative culture around your machine learning initiatives. Good luck, RBN!\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file from parent directory\n",
    "load_dotenv(dotenv_path='./.env.example')\n",
    "\n",
    "API_KEY = os.environ[\"API_KEY\"]\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents='Hi name is RBN. I\\'m practicing to learn Mlops. Can you tell me about MLOps?'\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1185a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DefaultVerifyPaths(cafile=None, capath=None, openssl_cafile_env='SSL_CERT_FILE', openssl_cafile='C:\\\\Program Files\\\\Common Files\\\\SSL/cert.pem', openssl_capath_env='SSL_CERT_DIR', openssl_capath='C:\\\\Program Files\\\\Common Files\\\\SSL/certs')\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "print(ssl.get_default_verify_paths())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f9f3c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLOps (Machine Learning Operations) is a set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently. It's an extension of the DevOps methodology to include Machine Learning, covering the entire lifecycle from data preparation to model deployment, monitoring, and retraining.\n",
      "\n",
      "## What is MLOps?\n",
      "\n",
      "In essence, MLOps bridges the gap between data scientists (who build models) and operations engineers (who deploy and manage systems). It focuses on **automating and streamlining the process of taking ML models from experimentation to production and keeping them healthy and performing over time.**\n",
      "\n",
      "**Why is MLOps Needed? (Problems it Solves)**\n",
      "\n",
      "Traditional software development (and thus DevOps) deals with static code. Machine Learning introduces several unique challenges:\n",
      "\n",
      "1.  **Data Dependency:** ML models are highly dependent on data. Changes in data distribution (data drift, concept drift) can degrade model performance without any code changes.\n",
      "2.  **Experimentation:** Data scientists iterate rapidly, train many models, and track numerous experiments, which can be hard to manage and reproduce.\n",
      "3.  **Reproducibility:** Reproducing an ML model requires not just the code, but also the exact data, dependencies, environment, and hyper-parameters used during training.\n",
      "4.  **Version Control:** Beyond code, you need to version control data, models, and environments.\n",
      "5.  **Monitoring:** Monitoring not just uptime and latency, but also model performance (accuracy, precision, recall), data quality, and potential biases.\n",
      "6.  **Deployment Complexity:** Models often require specific serving infrastructure (e.g., APIs, batch prediction, edge devices).\n",
      "7.  **Retraining:** Models degrade over time and need to be retrained periodically with new data, which requires an automated pipeline.\n",
      "8.  **Collaboration:** Seamless collaboration between data scientists, ML engineers, and operations teams is crucial.\n",
      "\n",
      "**Key Components and Phases of MLOps**\n",
      "\n",
      "MLOps encompasses several interconnected components throughout the ML lifecycle:\n",
      "\n",
      "1.  **Data Engineering:**\n",
      "    *   Data ingestion, cleaning, transformation, and validation.\n",
      "    *   Feature engineering and creation of feature stores.\n",
      "    *   Data versioning and lineage tracking.\n",
      "2.  **ML Experimentation & Development:**\n",
      "    *   Automated experiment tracking (metrics, parameters, artifacts).\n",
      "    *   Model versioning and registration.\n",
      "    *   Code version control (Git).\n",
      "    *   Environment management (conda, virtualenv, Docker).\n",
      "3.  **ML CI/CD (Continuous Integration/Continuous Delivery for ML):**\n",
      "    *   Automated building, testing, and deployment of ML pipelines and models.\n",
      "    *   **CI for ML:** Testing code, data, model quality, and integration.\n",
      "    *   **CD for ML:** Automated deployment of models to various environments (staging, production).\n",
      "4.  **ML Model Serving & Deployment:**\n",
      "    *   API endpoints for real-time inference (REST APIs, gRPC).\n",
      "    *   Batch prediction systems.\n",
      "    *   Deployment to edge devices.\n",
      "    *   A/B testing, canary deployments, blue/green deployments for models.\n",
      "5.  **ML Model Monitoring & Management:**\n",
      "    *   Monitoring model performance (accuracy, latency, throughput, errors).\n",
      "    *   Detecting data drift and concept drift.\n",
      "    *   Monitoring data quality and integrity.\n",
      "    *   Alerting systems.\n",
      "    *   Model explainability (interpreting why a model made a certain prediction).\n",
      "6.  **Orchestration & Workflow Management:**\n",
      "    *   Tools to define, schedule, and manage complex ML pipelines (e.g., data preprocessing, training, evaluation, deployment).\n",
      "7.  **Infrastructure Management:**\n",
      "    *   Managing compute resources (CPUs, GPUs), storage, and networking, often in cloud environments (AWS, Azure, GCP) or Kubernetes.\n",
      "\n",
      "## How a Beginner Can Start Learning MLOps\n",
      "\n",
      "MLOps can seem overwhelming due to the number of tools and concepts involved. The key is to **start simple, understand the core problems, and build practical projects incrementally.**\n",
      "\n",
      "Here's a structured path for a beginner:\n",
      "\n",
      "### Phase 0: Prerequisites (Foundation First!)\n",
      "\n",
      "Before diving into MLOps specific tools, ensure you have a solid grasp of these fundamentals:\n",
      "\n",
      "1.  **Python Programming:** MLOps is heavily Python-centric.\n",
      "2.  **Basic Machine Learning Concepts:** Understand the ML lifecycle (data collection, preprocessing, model training, evaluation, prediction) and common algorithms.\n",
      "3.  **Git & GitHub:** Version control is non-negotiable for any software development, including MLOps. Learn branching, merging, pull requests.\n",
      "4.  **Linux Command Line Basics:** You'll be interacting with servers and containers.\n",
      "5.  **Cloud Fundamentals (Optional but Recommended):** Choose one cloud provider (AWS, Azure, GCP) and understand basic services like VMs (EC2, Compute Engine), storage (S3, Blob Storage), and networking.\n",
      "\n",
      "### Phase 1: Master Core MLOps Building Blocks (Local First)\n",
      "\n",
      "Focus on fundamental practices and tools that enable MLOps, even on your local machine.\n",
      "\n",
      "1.  **Containerization (Docker):**\n",
      "    *   **Why:** Ensures your ML models and their dependencies run consistently across different environments. Solves \"it works on my machine\" problems.\n",
      "    *   **What to Learn:** Dockerfiles, building images, running containers, Docker Compose (for multi-container applications).\n",
      "    *   **Project Idea:** Containerize a simple Python Flask/FastAPI application that serves a pre-trained scikit-learn model.\n",
      "2.  **Python Packaging & Environments:**\n",
      "    *   **Why:** To create reproducible environments and share your code as packages.\n",
      "    *   **What to Learn:** `pip`, `requirements.txt`, `venv`, `conda`, `setup.py`/`pyproject.toml` for creating your own packages.\n",
      "    *   **Project Idea:** Package your ML model's inference code into a reusable Python package.\n",
      "3.  **Experiment Tracking & Model Registry (MLflow is excellent for beginners):**\n",
      "    *   **Why:** To organize, compare, and reproduce different ML experiments and manage model versions.\n",
      "    *   **What to Learn:** `mlflow.start_run()`, `mlflow.log_param()`, `mlflow.log_metric()`, `mlflow.sklearn.log_model()`, MLflow UI, Model Registry.\n",
      "    *   **Project Idea:** Retrain your scikit-learn model, tracking hyper-parameters, metrics, and saving the model to MLflow.\n",
      "\n",
      "### Phase 2: Introduce Automation & Pipelines\n",
      "\n",
      "Now, combine the building blocks into automated workflows.\n",
      "\n",
      "1.  **Orchestration (Airflow or Prefect):**\n",
      "    *   **Why:** To define, schedule, and monitor complex sequences of tasks (e.g., data preprocessing, model training, evaluation).\n",
      "    *   **What to Learn:** DAGs (Directed Acyclic Graphs), tasks, operators, scheduling.\n",
      "    *   **Project Idea:** Create a simple Airflow DAG that:\n",
      "        1.  Fetches data.\n",
      "        2.  Trains your scikit-learn model using MLflow to track.\n",
      "        3.  Evaluates the model.\n",
      "2.  **Data Versioning (DVC - Data Version Control):**\n",
      "    *   **Why:** Versioning data is as crucial as versioning code.\n",
      "    *   **What to Learn:** `dvc init`, `dvc add`, `dvc push`, `dvc pull`, integrating with Git.\n",
      "    *   **Project Idea:** Add DVC to your existing project to version the training data used for your model.\n",
      "3.  **Basic CI/CD with GitHub Actions (or GitLab CI/CD, Jenkins):**\n",
      "    *   **Why:** To automate testing and deployment whenever code changes.\n",
      "    *   **What to Learn:** Workflows, jobs, steps, triggers, runners.\n",
      "    *   **Project Idea:** Set up a GitHub Actions workflow that:\n",
      "        1.  Lints your Python code.\n",
      "        2.  Runs unit tests.\n",
      "        3.  Builds your Docker image for the model serving API.\n",
      "\n",
      "### Phase 3: Deployment, Monitoring, and Scaling\n",
      "\n",
      "Move beyond local development to production-like environments.\n",
      "\n",
      "1.  **Model Serving (FastAPI is popular):**\n",
      "    *   **Why:** To expose your trained model as an API for real-time predictions.\n",
      "    *   **What to Learn:** FastAPI basics, Pydantic for data validation.\n",
      "    *   **Project Idea:** Build a FastAPI app that loads your best model from MLflow Model Registry and serves predictions. Containerize it with Docker.\n",
      "2.  **Basic Cloud Deployment:**\n",
      "    *   **Why:** To deploy your containerized model API to a cloud environment.\n",
      "    *   **What to Learn:** Deploying a Docker image to a simple VM (e.g., AWS EC2, GCP Compute Engine, Azure VM) and setting up a basic web server (nginx) or using a PaaS (Platform as a Service) like AWS Fargate, Google Cloud Run.\n",
      "    *   **Project Idea:** Deploy your FastAPI Docker container to a cloud VM or serverless container service.\n",
      "3.  **Model Monitoring (Conceptual First):**\n",
      "    *   **Why:** Crucial for detecting performance degradation, data drift, and errors.\n",
      "    *   **What to Learn:** Types of monitoring (performance, data drift, concept drift), metrics (accuracy, RMSE, precision, recall), logging inference requests and predictions. Tools like Prometheus/Grafana (for infrastructure), custom logging for ML metrics.\n",
      "    *   **Project Idea:** Augment your FastAPI app to log input data, predictions, and potentially true labels (if available later) to a simple file or a cloud logging service.\n",
      "\n",
      "### Advanced Topics (Once you're comfortable with the above)\n",
      "\n",
      "*   **Kubernetes (k8s):** For orchestrating containerized applications at scale.\n",
      "*   **Specialized MLOps Platforms:** AWS SageMaker, Google Vertex AI, Azure Machine Learning. These integrate many MLOps components.\n",
      "*   **Feature Stores:** For managing and serving features consistently for training and inference (e.g., Feast).\n",
      "*   **Advanced CI/CD:** Canary deployments, A/B testing for models.\n",
      "*   **Model Explainability (XAI):** Tools like SHAP, LIME.\n",
      "\n",
      "### Recommended Resources for Beginners\n",
      "\n",
      "*   **Online Courses:**\n",
      "    *   **Coursera: MLOps Specialization by Google Cloud:** A fantastic comprehensive course.\n",
      "    *   **Udemy/edX/DataCamp:** Look for courses specifically titled \"MLOps Basics\" or \"Production Machine Learning.\"\n",
      "*   **Books:**\n",
      "    *   \"Building Machine Learning Powered Applications\" by Emmanuel Ameisen.\n",
      "    *   \"Introducing MLOps\" by Mark Treveil et al.\n",
      "*   **Blogs & Articles:**\n",
      "    *   Google Cloud MLOps whitepapers and blogs.\n",
      "    *   Towards Data Science articles on MLOps.\n",
      "    *   MLflow, DVC, FastAPI, Docker official documentation.\n",
      "*   **Communities:**\n",
      "    *   Join the MLOps.Community on Slack.\n",
      "    *   Follow MLOps practitioners on LinkedIn and Twitter.\n",
      "\n",
      "### Learning Mindset\n",
      "\n",
      "*   **Hands-on, Hands-on, Hands-on:** Don't just read; build things. Replicate tutorials, then try to apply them to your own simple ML projects.\n",
      "*   **Start Simple:** Don't try to implement every MLOps tool at once. Pick one problem (e.g., \"how do I track my experiments?\") and learn the best tool for it.\n",
      "*   **Understand the \"Why\":** For every tool or practice, ask why it's needed and what problem it solves.\n",
      "*   **Iterate:** MLOps is an iterative process. Your first pipeline won't be perfect. Learn, refine, and improve.\n",
      "\n",
      "By following this structured approach, you can gradually build your MLOps skills and gain confidence in deploying and managing machine learning models in real-world scenarios.\n"
     ]
    }
   ],
   "source": [
    "User_prompt = 'what is mlops and how a beginner can start learning mlops?'\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=User_prompt\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e8ae76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "As an MLOps expert, here's a concise update on the latest market trends:\n",
      "\n",
      "1.  **Generative AI MLOps:** The biggest shift is adapting MLOps for Large Language Models (LLMs) and Generative AI. This means new challenges around:\n",
      "    *   **Prompt Engineering Versioning:** Managing and tracking different prompt strategies.\n",
      "    *   **Fine-tuning Workflows:** Streamlining the process of adapting foundation models.\n",
      "    *   **Monitoring \"Prompt Drift\" and Hallucinations:** Detecting when LLM outputs degrade due to input changes or inherent model issues.\n",
      "    *   **Cost Optimization for Inference:** Managing the high compute demands of serving large models.\n",
      "\n",
      "2.  **Responsible AI & Governance (RAI/AI Governance):** There's a rapidly increasing focus on ethical AI. MLOps is critical for:\n",
      "    *   **Model Explainability (XAI):** Ensuring models can be understood.\n",
      "    *   **Fairness & Bias Detection:** Identifying and mitigating unfair outcomes.\n",
      "    *   **Auditability & Compliance:** Tracking model decisions and meeting emerging regulations (e.g., EU AI Act readiness).\n",
      "\n",
      "3.  **Integrated Platforms & Simplification:** The market is seeing a push towards more unified MLOps platforms that integrate data, model development, deployment, and monitoring into a single, cohesive experience, reducing tool sprawl.\n",
      "\n",
      "4.  **Cost Optimization:** With larger models and increased AI adoption, optimizing compute resources, particularly for model training and inference, is a top priority for organizations.\n",
      "\n",
      "5.  **Data-Centric MLOps Reinforcement:** The importance of high-quality data pipelines, feature stores, and robust data versioning remains paramount, especially with GenAI's reliance on vast datasets for pre-training and fine-tuning.\n",
      "\n",
      "In essence, MLOps is rapidly evolving to specifically address the unique demands and governance needs of advanced AI, particularly Generative AI, while continuing its core mission of bringing reliable and scalable machine learning to production.\n"
     ]
    }
   ],
   "source": [
    "User_prompt_2= 'What is latest news about MLOps? in the market'\n",
    "print('='*100)\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.5-flash',\n",
    "    contents=User_prompt_2,\n",
    "    config=types.GenerateContentConfig(system_instruction=\"You are helpful assistant who is expert in MLOps and always provide latest information about MLOps in short and concise way.\"\n",
    "    )\n",
    ")\n",
    "print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlops-venv)",
   "language": "python",
   "name": "mlops-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
